{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import torch.nn.utils.parametrize as parametrize"
      ],
      "metadata": {
        "id": "TZFOlb-JW8Wd"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR10 normalization values\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
        "                         (0.2470, 0.2435, 0.2616))\n",
        "])\n",
        "\n",
        "# Load CIFAR10 dataset\n",
        "cifar_trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(cifar_trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "cifar_testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(cifar_testset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Define device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "WmXz5KU9Y3Y9"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR10 input (32*32*3 = 3072)\n",
        "class classifier(nn.Module):\n",
        "    def __init__(self, hidden_size_1=1000, hidden_size_2=2000):\n",
        "        super(classifier,self).__init__()\n",
        "        self.linear1 = nn.Linear(32*32*3, hidden_size_1)\n",
        "        self.linear2 = nn.Linear(hidden_size_1, hidden_size_2)\n",
        "        self.linear3 = nn.Linear(hidden_size_2, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, img):\n",
        "        x = img.view(-1, 32*32*3)\n",
        "        x = self.relu(self.linear1(x))\n",
        "        x = self.relu(self.linear2(x))\n",
        "        x = self.linear3(x)\n",
        "        return x\n",
        "\n",
        "net = classifier().to(device)"
      ],
      "metadata": {
        "id": "Dn3LbMb7ZC6E"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "def train_model(train_loader, net, epochs=5, total_iterations_limit=None):\n",
        "    cross_el = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "    total_iterations = 0\n",
        "    for epoch in range(epochs):\n",
        "        net.train()\n",
        "        loss_sum = 0\n",
        "        num_iterations = 0\n",
        "        data_iterator = tqdm(train_loader, desc=f'Epoch {epoch+1}')\n",
        "        if total_iterations_limit is not None:\n",
        "            data_iterator.total = total_iterations_limit\n",
        "\n",
        "        for data in data_iterator:\n",
        "            num_iterations += 1\n",
        "            total_iterations += 1\n",
        "            x, y = data\n",
        "            x, y = x.to(device), y.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = net(x.view(-1, 32*32*3))\n",
        "            loss = cross_el(output, y)\n",
        "            loss_sum += loss.item()\n",
        "            avg_loss = loss_sum / num_iterations\n",
        "            data_iterator.set_postfix(loss=avg_loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if total_iterations_limit is not None and total_iterations >= total_iterations_limit:\n",
        "                return\n",
        "\n",
        "# Train baseline\n",
        "train_model(train_loader, net, epochs=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qC3pI5-ayOT",
        "outputId": "3df2e67a-a0ac-436e-a492-cd8d7ee2c4e5"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 782/782 [00:17<00:00, 45.83it/s, loss=1.69]\n",
            "Epoch 2: 100%|██████████| 782/782 [00:17<00:00, 44.01it/s, loss=1.49]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save original weights\n",
        "original_weights = {}\n",
        "for name, param in net.named_parameters():\n",
        "    original_weights[name] = param.clone().detach()"
      ],
      "metadata": {
        "id": "zwJspxXVa48Q"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test loop\n",
        "def test_model():\n",
        "    correct, total = 0, 0\n",
        "    wrong_counts = [0 for i in range(10)]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(test_loader, desc='Testing'):\n",
        "            x, y = data\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            output = net(x.view(-1, 32*32*3))\n",
        "            for idx, i in enumerate(output):\n",
        "                if torch.argmax(i) == y[idx]:\n",
        "                    correct += 1\n",
        "                else:\n",
        "                    wrong_counts[y[idx]] += 1\n",
        "                total += 1\n",
        "    print(f'Accuracy: {round(correct/total, 3)}')\n",
        "    for i in range(len(wrong_counts)):\n",
        "        print(f'wrong counts for class {i}: {wrong_counts[i]}')\n",
        "\n",
        "test_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4eR6jGta_n-",
        "outputId": "4bf77720-6fdc-48c6-be73-76cc8fde8d32"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 157/157 [00:03<00:00, 48.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.471\n",
            "wrong counts for class 0: 534\n",
            "wrong counts for class 1: 383\n",
            "wrong counts for class 2: 746\n",
            "wrong counts for class 3: 749\n",
            "wrong counts for class 4: 439\n",
            "wrong counts for class 5: 643\n",
            "wrong counts for class 6: 623\n",
            "wrong counts for class 7: 433\n",
            "wrong counts for class 8: 289\n",
            "wrong counts for class 9: 449\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count parameters\n",
        "total_parameters_original = 0\n",
        "for index, layer in enumerate([net.linear1, net.linear2, net.linear3]):\n",
        "    total_parameters_original += layer.weight.nelement() + layer.bias.nelement()\n",
        "    print(f'Layer {index+1}: W: {layer.weight.shape} + B: {layer.bias.shape}')\n",
        "print(f'Total number of parameters: {total_parameters_original:,}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRm9zDaCbF_n",
        "outputId": "171fee6f-02c8-477c-b010-5a88d66c3228"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 1: W: torch.Size([1000, 3072]) + B: torch.Size([1000])\n",
            "Layer 2: W: torch.Size([2000, 1000]) + B: torch.Size([2000])\n",
            "Layer 3: W: torch.Size([10, 2000]) + B: torch.Size([10])\n",
            "Total number of parameters: 5,095,010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LoRA Parametrization\n",
        "class LoRAParametrization(nn.Module):\n",
        "    def __init__(self, features_in, features_out, rank=1, alpha=1, device='cpu'):\n",
        "        super().__init__()\n",
        "        self.lora_A = nn.Parameter(torch.zeros((rank,features_out)).to(device))\n",
        "        self.lora_B = nn.Parameter(torch.zeros((features_in, rank)).to(device))\n",
        "        nn.init.normal_(self.lora_A, mean=0, std=1)\n",
        "        self.scale = alpha / rank\n",
        "        self.enabled = True\n",
        "\n",
        "    def forward(self, original_weights):\n",
        "        if self.enabled:\n",
        "            return original_weights + torch.matmul(self.lora_B, self.lora_A).view(original_weights.shape) * self.scale\n",
        "        else:\n",
        "            return original_weights\n",
        "\n",
        "def linear_layer_parameterization(layer, device, rank=1, lora_alpha=1):\n",
        "    features_in, features_out = layer.weight.shape\n",
        "    return LoRAParametrization(\n",
        "        features_in, features_out, rank=rank, alpha=lora_alpha, device=device\n",
        "    )\n",
        "\n",
        "def enable_disable_lora(enabled=True):\n",
        "    for layer in [net.linear1, net.linear2, net.linear3]:\n",
        "        layer.parametrizations[\"weight\"][0].enabled = enabled\n",
        "\n"
      ],
      "metadata": {
        "id": "bJr7jTS8bPdb"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Register parametrizations\n",
        "parametrize.register_parametrization(\n",
        "    net.linear1, \"weight\", linear_layer_parameterization(net.linear1, device)\n",
        ")\n",
        "parametrize.register_parametrization(\n",
        "    net.linear2, \"weight\", linear_layer_parameterization(net.linear2, device)\n",
        ")\n",
        "parametrize.register_parametrization(\n",
        "    net.linear3, \"weight\", linear_layer_parameterization(net.linear3, device)\n",
        ")\n",
        "\n",
        "# Count parameters with LoRA\n",
        "total_parameters_lora, total_parameters_non_lora = 0, 0\n",
        "for index, layer in enumerate([net.linear1, net.linear2, net.linear3]):\n",
        "    total_parameters_lora += layer.parametrizations[\"weight\"][0].lora_A.nelement() + layer.parametrizations[\"weight\"][0].lora_B.nelement()\n",
        "    total_parameters_non_lora += layer.weight.nelement() + layer.bias.nelement()\n",
        "    print(f'Layer {index+1}: W: {layer.weight.shape} + B: {layer.bias.shape} + '\n",
        "          f'Lora_A: {layer.parametrizations[\"weight\"][0].lora_A.shape} + '\n",
        "          f'Lora_B: {layer.parametrizations[\"weight\"][0].lora_B.shape}')\n",
        "\n",
        "assert total_parameters_non_lora == total_parameters_original\n",
        "print(f'Total number of parameters (original): {total_parameters_non_lora:,}')\n",
        "print(f'Total number of parameters (original + LoRA): {total_parameters_lora + total_parameters_non_lora:,}')\n",
        "print(f'Parameters introduced by LoRA: {total_parameters_lora:,}')\n",
        "parameters_incremment = (total_parameters_lora / total_parameters_non_lora) * 100\n",
        "print(f'Parameters incremment: {parameters_incremment:.3f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAeBqpzpbWjf",
        "outputId": "8d3c740d-9ead-4b90-c002-e2c2dfd4d8ab"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 1: W: torch.Size([1000, 3072]) + B: torch.Size([1000]) + Lora_A: torch.Size([1, 3072]) + Lora_B: torch.Size([1000, 1])\n",
            "Layer 2: W: torch.Size([2000, 1000]) + B: torch.Size([2000]) + Lora_A: torch.Size([1, 1000]) + Lora_B: torch.Size([2000, 1])\n",
            "Layer 3: W: torch.Size([10, 2000]) + B: torch.Size([10]) + Lora_A: torch.Size([1, 2000]) + Lora_B: torch.Size([10, 1])\n",
            "Total number of parameters (original): 5,095,010\n",
            "Total number of parameters (original + LoRA): 5,104,092\n",
            "Parameters introduced by LoRA: 9,082\n",
            "Parameters incremment: 0.178%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze non-LoRA params\n",
        "for name, param in net.named_parameters():\n",
        "    if 'lora' not in name:\n",
        "        print(f'Freezing non-LoRA parameter {name}')\n",
        "        param.requires_grad = False\n",
        "\n",
        "# Fine-tune only on CIFAR10 class \"cat\" (label 3)\n",
        "cifar_trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "exclude_indices = torch.tensor(cifar_trainset.targets) == 5\n",
        "cifar_trainset.data = cifar_trainset.data[exclude_indices]\n",
        "cifar_trainset.targets = torch.tensor(cifar_trainset.targets)[exclude_indices]\n",
        "train_loader = torch.utils.data.DataLoader(cifar_trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Train LoRA on class 3 (cat) only\n",
        "train_model(train_loader, net, epochs=1, total_iterations_limit=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCMIBshlbgnL",
        "outputId": "3d30fb30-28fa-4981-c609-1b4aa632f04f"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Freezing non-LoRA parameter linear1.bias\n",
            "Freezing non-LoRA parameter linear1.parametrizations.weight.original\n",
            "Freezing non-LoRA parameter linear2.bias\n",
            "Freezing non-LoRA parameter linear2.parametrizations.weight.original\n",
            "Freezing non-LoRA parameter linear3.bias\n",
            "Freezing non-LoRA parameter linear3.parametrizations.weight.original\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  79%|███████▉  | 79/100 [00:01<00:00, 40.45it/s, loss=0.334]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check frozen params unchanged\n",
        "assert torch.all(net.linear1.parametrizations.weight.original == original_weights['linear1.weight'])\n",
        "assert torch.all(net.linear2.parametrizations.weight.original == original_weights['linear2.weight'])\n",
        "assert torch.all(net.linear3.parametrizations.weight.original == original_weights['linear3.weight'])\n",
        "\n",
        "# Enable/disable LoRA checks\n",
        "enable_disable_lora(enabled=True)\n",
        "assert torch.equal(net.linear1.weight, net.linear1.parametrizations.weight.original + (net.linear1.parametrizations.weight[0].lora_B @ net.linear1.parametrizations.weight[0].lora_A) * net.linear1.parametrizations.weight[0].scale)\n",
        "\n",
        "enable_disable_lora(enabled=False)\n",
        "assert torch.equal(net.linear1.weight, original_weights['linear1.weight'])\n",
        "\n",
        "print(\"\\nWith LoRA finetuning\")\n",
        "# Test LoRA enabled\n",
        "enable_disable_lora(enabled=True)\n",
        "test_model()\n",
        "\n",
        "print(\"\\nWithout LoRA finetuning\")\n",
        "# Test LoRA disabled\n",
        "enable_disable_lora(enabled=False)\n",
        "test_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNtfzy3lb7gG",
        "outputId": "0fbb522d-70a9-458f-df02-70f02725816e"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "With LoRA finetuning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 157/157 [00:04<00:00, 37.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.139\n",
            "wrong counts for class 0: 987\n",
            "wrong counts for class 1: 923\n",
            "wrong counts for class 2: 1000\n",
            "wrong counts for class 3: 998\n",
            "wrong counts for class 4: 994\n",
            "wrong counts for class 5: 9\n",
            "wrong counts for class 6: 995\n",
            "wrong counts for class 7: 939\n",
            "wrong counts for class 8: 876\n",
            "wrong counts for class 9: 888\n",
            "\n",
            "Without LoRA finetuning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 157/157 [00:03<00:00, 48.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.471\n",
            "wrong counts for class 0: 534\n",
            "wrong counts for class 1: 383\n",
            "wrong counts for class 2: 746\n",
            "wrong counts for class 3: 749\n",
            "wrong counts for class 4: 439\n",
            "wrong counts for class 5: 643\n",
            "wrong counts for class 6: 623\n",
            "wrong counts for class 7: 433\n",
            "wrong counts for class 8: 289\n",
            "wrong counts for class 9: 449\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "computePreferences": null,
      "dashboards": [],
      "environmentMetadata": {
        "base_environment": "",
        "environment_version": "3"
      },
      "inputWidgetPreferences": null,
      "language": "python",
      "notebookMetadata": {
        "pythonIndentUnit": 2
      },
      "notebookName": "lora",
      "widgets": {}
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}